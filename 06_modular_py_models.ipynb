{"cells":[{"cell_type":"markdown","source":["## This ipynb turns cells into python codes for reusability\n","`%%writefile [path.py]` write a cell into a py file which can be reused later, and run it once will suffice. For each section:\n","1. cells: original ipynb cells\n","2. scripts: use `%%writefile` to turn necessary cells into scripts\n","3. use scripts: a sample use case importing the scripts"],"metadata":{"id":"hUYQwyi4una-"}},{"cell_type":"markdown","source":["### 0. use the scripts\n","Run this is enough, while all other sections below simply create scripts"],"metadata":{"id":"RPwOibOMok8G"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BffXfgk0sF9Y","executionInfo":{"status":"ok","timestamp":1736571398951,"user_tz":480,"elapsed":1593,"user":{"displayName":"Maohe Jiang","userId":"14592769344524725558"}},"outputId":"ca2cdbb1-3711-4680-d159-227922ae950b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!python /content/drive/MyDrive/pytorch/06_modular_py_models/train.py /content/drive/MyDrive/pytorch/data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XEZyfzbxphoG","executionInfo":{"status":"ok","timestamp":1736571419354,"user_tz":480,"elapsed":20407,"user":{"displayName":"Maohe Jiang","userId":"14592769344524725558"}},"outputId":"7fd1fa81-147a-46bd-8ac3-291be3fa6b39"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["I am a model\n","/content/drive/MyDrive/pytorch/data/pizza_steak_sushi directory exists.\n","  0% 0/5 [00:00<?, ?it/s]Epoch: 1 | train_loss: 1.0923 | train_acc: 0.3911 | test_loss: 1.0726 | test_acc: 0.4133\n"," 20% 1/5 [00:02<00:10,  2.57s/it]Epoch: 2 | train_loss: 1.0265 | train_acc: 0.5111 | test_loss: 1.0164 | test_acc: 0.4267\n"," 40% 2/5 [00:05<00:07,  2.64s/it]Epoch: 3 | train_loss: 0.9600 | train_acc: 0.5200 | test_loss: 0.9912 | test_acc: 0.4667\n"," 60% 3/5 [00:07<00:04,  2.48s/it]Epoch: 4 | train_loss: 0.9154 | train_acc: 0.5600 | test_loss: 0.9777 | test_acc: 0.4267\n"," 80% 4/5 [00:10<00:02,  2.59s/it]Epoch: 5 | train_loss: 0.8891 | train_acc: 0.6000 | test_loss: 0.9873 | test_acc: 0.4800\n","100% 5/5 [00:13<00:00,  2.63s/it]\n","[INFO] Total training time: 13.172 seconds\n","[INFO] Saving model to: /content/drive/MyDrive/pytorch/models/6_modular_py_models_cells_tinyvgg.pth\n"]}]},{"cell_type":"code","source":["# add folder to path so one can import; this is for script uses\n","import sys\n","\n","directory_path = '/content/drive/MyDrive/pytorch/06_modular_py_models'\n","\n","if directory_path not in sys.path:\n","    sys.path.append(directory_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tSUNsyGotNMj","executionInfo":{"status":"ok","timestamp":1736571185704,"user_tz":480,"elapsed":280,"user":{"displayName":"Maohe Jiang","userId":"14592769344524725558"}},"outputId":"48312b4a-ce07-4ce7-822e-e7b6722969d5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["rmdir: failed to remove '/content/drive/MyDrive/pytorch/data/pizza_steak_sushi': Directory not empty\n"]}]},{"cell_type":"markdown","metadata":{"id":"1XgXFr97bCsI"},"source":["### 1. Get data\n"]},{"cell_type":"markdown","source":["#### 1.1 cells"],"metadata":{"id":"6EOwkDPwxmAW"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wl_jfPzVbGDS","outputId":"93826617-6417-44d4-956f-75160ce8d11c","executionInfo":{"status":"ok","timestamp":1736565334015,"user_tz":480,"elapsed":405,"user":{"displayName":"Maohe Jiang","userId":"14592769344524725558"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/pytorch/data/pizza_steak_sushi directory exists.\n"]}],"source":["import os\n","import zipfile\n","\n","from pathlib import Path\n","\n","import requests\n","\n","# Setup path to data folder\n","data_path = Path(\"/content/drive/MyDrive/pytorch/data\")\n","image_path = data_path / \"pizza_steak_sushi\"\n","\n","# If the image folder doesn't exist, download it and prepare it...\n","if image_path.is_dir():\n","    print(f\"{image_path} directory exists.\")\n","else:\n","    print(f\"Did not find {image_path} directory, creating one...\")\n","    image_path.mkdir(parents=True, exist_ok=True)\n","\n","    # Download pizza, steak, sushi data\n","    with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n","        request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n","        print(\"Downloading pizza, steak, sushi data...\")\n","        f.write(request.content)\n","\n","    # Unzip pizza, steak, sushi data\n","    with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n","        print(\"Unzipping pizza, steak, sushi data...\")\n","        zip_ref.extractall(image_path)\n","\n","    # Remove zip file\n","    os.remove(data_path / \"pizza_steak_sushi.zip\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8qYMdiBMbde0","outputId":"f4ec3127-66df-42c8-f0bf-107263588c7b","executionInfo":{"status":"ok","timestamp":1736554958003,"user_tz":480,"elapsed":163,"user":{"displayName":"Maohe Jiang","userId":"14592769344524725558"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(PosixPath('/content/drive/MyDrive/pytorch/data/pizza_steak_sushi/train'),\n"," PosixPath('/content/drive/MyDrive/pytorch/data/pizza_steak_sushi/test'))"]},"metadata":{},"execution_count":4}],"source":["# Setup train and testing paths\n","train_dir = image_path / \"train\"\n","test_dir = image_path / \"test\"\n","\n","train_dir, test_dir"]},{"cell_type":"markdown","source":["#### 1.2 scripts"],"metadata":{"id":"sU8S3DGKxoYL"}},{"cell_type":"code","source":["%%writefile /content/drive/MyDrive/pytorch/06_modular_py_models/data_download.py\n","\"\"\"A file defining the download function\"\"\"\n","\n","import os\n","import zipfile\n","\n","import pathlib\n","from pathlib import Path\n","\n","import requests\n","\n","def download_sample_to_path(path: str):\n","    \"\"\"Given a path, download the pizza sushi steak data folder to the directory\n","\n","    Args:\n","        path: a string leading to the path\n","\n","    Returns:\n","        A tuple of (train_dir, test_dir)\n","    \"\"\"\n","\n","    data_path = Path(path)\n","    image_path = data_path / \"pizza_steak_sushi\"\n","\n","    # If the image folder doesn't exist, download it and prepare it...\n","    if image_path.is_dir():\n","        print(f\"{image_path} directory exists.\")\n","    else:\n","        print(f\"Did not find {image_path} directory, creating one...\")\n","        image_path.mkdir(parents=True, exist_ok=True)\n","\n","        # Download pizza, steak, sushi data\n","        with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n","            request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n","            print(\"Downloading pizza, steak, sushi data...\")\n","            f.write(request.content)\n","\n","        # Unzip pizza, steak, sushi data\n","        with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n","            print(\"Unzipping pizza, steak, sushi data...\")\n","            zip_ref.extractall(image_path)\n","\n","        # Remove zip file\n","        os.remove(data_path / \"pizza_steak_sushi.zip\")\n","\n","    train_dir = image_path / \"train\"\n","    test_dir = image_path / \"test\"\n","\n","    return train_dir, test_dir"],"metadata":{"id":"0rAYH_8dESt8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736568009405,"user_tz":480,"elapsed":154,"user":{"displayName":"Maohe Jiang","userId":"14592769344524725558"}},"outputId":"dd675afb-0ca1-4541-ba2c-d6dcc774f8fa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting /content/drive/MyDrive/pytorch/06_modular_py_models/data_download.py\n"]}]},{"cell_type":"markdown","source":["#### 1.3 use scripts"],"metadata":{"id":"g9v1vNRMgPWC"}},{"cell_type":"code","source":["import data_download\n","import pathlib\n","from pathlib import Path\n","\n","data_download.download_sample_to_path(\"/content/drive/MyDrive/pytorch/data\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lNRDA1hGgOyV","executionInfo":{"status":"ok","timestamp":1736568011650,"user_tz":480,"elapsed":275,"user":{"displayName":"Maohe Jiang","userId":"14592769344524725558"}},"outputId":"33dbc7da-b10c-4e26-e0fb-903c2e5b3965"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/pytorch/data/pizza_steak_sushi directory exists.\n"]},{"output_type":"execute_result","data":{"text/plain":["(PosixPath('/content/drive/MyDrive/pytorch/data/pizza_steak_sushi/train'),\n"," PosixPath('/content/drive/MyDrive/pytorch/data/pizza_steak_sushi/test'))"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"eYL6NynybU9Z"},"source":["### 2. Create Datasets and DataLoaders\n"]},{"cell_type":"markdown","source":["#### 2.1 cells"],"metadata":{"id":"t5fyS8xMv6FO"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DaOJOd-QbOQk","outputId":"e4fbf635-6f35-4f6a-ffd4-b2494d7e9e6c","executionInfo":{"status":"ok","timestamp":1736554403903,"user_tz":480,"elapsed":8247,"user":{"displayName":"Maohe Jiang","userId":"14592769344524725558"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Train data:\n","Dataset ImageFolder\n","    Number of datapoints: 225\n","    Root location: /content/drive/MyDrive/pytorch/data/pizza_steak_sushi/train\n","    StandardTransform\n","Transform: Compose(\n","               Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=True)\n","               ToTensor()\n","           )\n","Test data:\n","Dataset ImageFolder\n","    Number of datapoints: 75\n","    Root location: /content/drive/MyDrive/pytorch/data/pizza_steak_sushi/test\n","    StandardTransform\n","Transform: Compose(\n","               Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=True)\n","               ToTensor()\n","           )\n"]}],"source":["from torchvision import datasets, transforms\n","\n","# Create simple transform\n","data_transform = transforms.Compose([\n","    transforms.Resize((64, 64)),\n","    transforms.ToTensor(),\n","])\n","\n","# Use ImageFolder to create dataset(s)\n","train_data = datasets.ImageFolder(root=train_dir, # target folder of images\n","                                  transform=data_transform, # transforms to perform on data (images)\n","                                  target_transform=None) # transforms to perform on labels (if necessary)\n","\n","test_data = datasets.ImageFolder(root=test_dir,\n","                                 transform=data_transform)\n","\n","print(f\"Train data:\\n{train_data}\\nTest data:\\n{test_data}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eEln0VFmbfyY","outputId":"2f754967-b8b0-412a-884c-ad46b3cc7ec8","executionInfo":{"status":"ok","timestamp":1736554403904,"user_tz":480,"elapsed":14,"user":{"displayName":"Maohe Jiang","userId":"14592769344524725558"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['pizza', 'steak', 'sushi']"]},"metadata":{},"execution_count":8}],"source":["# Get class names as a list\n","class_names = train_data.classes\n","class_names"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IMGTFVr8bgwE","outputId":"4d54f14a-5ece-465a-b8a2-7fa10beea3a9","executionInfo":{"status":"ok","timestamp":1736554403904,"user_tz":480,"elapsed":11,"user":{"displayName":"Maohe Jiang","userId":"14592769344524725558"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'pizza': 0, 'steak': 1, 'sushi': 2}"]},"metadata":{},"execution_count":9}],"source":["# Can also get class names as a dict\n","class_dict = train_data.class_to_idx\n","class_dict"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6a8IW-IYbhGX","outputId":"894e739e-8ed9-4e1d-ed9a-899a04f47a15","executionInfo":{"status":"ok","timestamp":1736554403904,"user_tz":480,"elapsed":8,"user":{"displayName":"Maohe Jiang","userId":"14592769344524725558"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(225, 75)"]},"metadata":{},"execution_count":10}],"source":["# Check the lengths\n","len(train_data), len(test_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f1UxnvvmblUj","outputId":"31b24771-f85b-4904-dd12-b4a96591928b","executionInfo":{"status":"ok","timestamp":1736554404594,"user_tz":480,"elapsed":4,"user":{"displayName":"Maohe Jiang","userId":"14592769344524725558"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(<torch.utils.data.dataloader.DataLoader at 0x7af181b66920>,\n"," <torch.utils.data.dataloader.DataLoader at 0x7af181b66950>)"]},"metadata":{},"execution_count":11}],"source":["# Turn train and test Datasets into DataLoaders\n","from torch.utils.data import DataLoader\n","train_dataloader = DataLoader(dataset=train_data,\n","                              batch_size=1, # how many samples per batch?\n","                              num_workers=1, # how many subprocesses to use for data loading? (higher = more)\n","                              shuffle=True) # shuffle the data?\n","\n","test_dataloader = DataLoader(dataset=test_data,\n","                             batch_size=1,\n","                             num_workers=1,\n","                             shuffle=False) # don't usually need to shuffle testing data\n","\n","train_dataloader, test_dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JJKRqXNGbnI5","outputId":"4fb60b14-28c9-40a5-9f68-7d6d530c95e3","executionInfo":{"status":"ok","timestamp":1736554408015,"user_tz":480,"elapsed":304,"user":{"displayName":"Maohe Jiang","userId":"14592769344524725558"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Image shape: torch.Size([1, 3, 64, 64]) -> [batch_size, color_channels, height, width]\n","Label shape: torch.Size([1])\n"]}],"source":["# Check out single image size/shape\n","img, label = next(iter(train_dataloader))\n","\n","# Batch size will now be 1, try changing the batch_size parameter above and see what happens\n","print(f\"Image shape: {img.shape} -> [batch_size, color_channels, height, width]\")\n","print(f\"Label shape: {label.shape}\")"]},{"cell_type":"markdown","source":["#### 2.2 scripts"],"metadata":{"id":"GZf8dcE4wo9r"}},{"cell_type":"code","source":["%%writefile /content/drive/MyDrive/pytorch/06_modular_py_models/data_setup.py\n","\"\"\"\n","Contains functionality for creating PyTorch DataLoader\n","\"\"\"\n","import os\n","\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","\n","NUM_WORKERS = os.cpu_count()\n","\n","def create_dataloaders(train_dir, test_dir, transform: transforms.Compose,\n","                       batch_size: int, num_workers = NUM_WORKERS):\n","    \"\"\"Creates training and testing loaders\n","\n","    Takes in a training directory and a testing directory, turns into PyTorch\n","    Datasets and Dataloaders\n","\n","    Args:\n","        train_dir: path to training directory\n","        test_dir: path to testing directory\n","        transform: the transform to perform on training and testing data\n","        batch_size: number of samples per batch\n","        num_workers: num_workers per data loader\n","\n","    Returns:\n","        A tuple of (train_loader, test_loader, class_names).\n","        Class_names is a list of classes\n","    \"\"\"\n","    train_data = datasets.ImageFolder(root=train_dir, # target folder of images\n","                                    transform=transform) # transforms to perform on data (images)\n","\n","    test_data = datasets.ImageFolder(root=test_dir,\n","                                    transform=transform)\n","    class_names = train_data.classes\n","    train_dataloader = DataLoader(dataset=train_data,\n","                                batch_size=1, # how many samples per batch?\n","                                num_workers=num_workers, # how many subprocesses to use for data loading? (higher = more)\n","                                shuffle=True, # shuffle the data?\n","                                pin_memory = True)\n","\n","    test_dataloader = DataLoader(dataset=test_data,\n","                                batch_size=1,\n","                                num_workers=num_workers,\n","                                shuffle=False, # don't usually need to shuffle testing data\n","                                pin_memory = True)\n","    return train_dataloader, test_dataloader, class_names"],"metadata":{"id":"SHwPCZESwulM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736570499683,"user_tz":480,"elapsed":148,"user":{"displayName":"Maohe Jiang","userId":"14592769344524725558"}},"outputId":"64ae8ea4-602c-49e9-ef08-720698eb5c0c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting /content/drive/MyDrive/pytorch/06_modular_py_models/data_setup.py\n"]}]},{"cell_type":"markdown","source":["#### 2.3 use script"],"metadata":{"id":"ApnwmVd7cTJ3"}},{"cell_type":"code","source":["# use case\n","import torchvision\n","from torchvision import transforms\n","from data_setup import create_dataloaders\n","\n","train_path = '/content/drive/MyDrive/pytorch/data/pizza_steak_sushi/train'\n","test_path = '/content/drive/MyDrive/pytorch/data/pizza_steak_sushi/test'\n","transform = transforms.Compose([\n","    transforms.Resize((64, 64)),\n","    transforms.ToTensor()\n","])\n","\n","train_loader, eval_loader, class_names = create_dataloaders(train_path, test_path, transform, 32, 0)\n","train_loader, eval_loader, class_names"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Za1T5zY2bFNh","executionInfo":{"status":"ok","timestamp":1736568028702,"user_tz":480,"elapsed":5699,"user":{"displayName":"Maohe Jiang","userId":"14592769344524725558"}},"outputId":"8b48a80e-19fe-4dbf-d6b6-d19d148cdbfc"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(<torch.utils.data.dataloader.DataLoader at 0x7f65c15c38b0>,\n"," <torch.utils.data.dataloader.DataLoader at 0x7f65c15c34f0>,\n"," ['pizza', 'steak', 'sushi'])"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"gAQLp1dCbrY0"},"source":["### 3. Define Model"]},{"cell_type":"markdown","source":["#### 3.1 cells"],"metadata":{"id":"I__q_b7IdW5S"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z6i2xWcwbvom"},"outputs":[],"source":["import torch\n","\n","from torch import nn\n","\n","class TinyVGG(nn.Module):\n","  \"\"\"Creates the TinyVGG architecture.\n","\n","  Replicates the TinyVGG architecture from the CNN explainer website in PyTorch.\n","  See the original architecture here: https://poloclub.github.io/cnn-explainer/\n","\n","  Args:\n","    input_shape: An integer indicating number of input channels.\n","    hidden_units: An integer indicating number of hidden units between layers.\n","    output_shape: An integer indicating number of output units.\n","  \"\"\"\n","  def __init__(self, input_shape: int, hidden_units: int, output_shape: int) -> None:\n","      super().__init__()\n","      self.conv_block_1 = nn.Sequential(\n","          nn.Conv2d(in_channels=input_shape,\n","                    out_channels=hidden_units,\n","                    kernel_size=3, # how big is the square that's going over the image?\n","                    stride=1, # default\n","                    padding=0), # options = \"valid\" (no padding) or \"same\" (output has same shape as input) or int for specific number\n","          nn.ReLU(),\n","          nn.Conv2d(in_channels=hidden_units,\n","                    out_channels=hidden_units,\n","                    kernel_size=3,\n","                    stride=1,\n","                    padding=0),\n","          nn.ReLU(),\n","          nn.MaxPool2d(kernel_size=2,\n","                        stride=2) # default stride value is same as kernel_size\n","      )\n","      self.conv_block_2 = nn.Sequential(\n","          nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=0),\n","          nn.ReLU(),\n","          nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=0),\n","          nn.ReLU(),\n","          nn.MaxPool2d(2)\n","      )\n","      self.classifier = nn.Sequential(\n","          nn.Flatten(),\n","          # Where did this in_features shape come from?\n","          # It's because each layer of our network compresses and changes the shape of our inputs data.\n","          nn.Linear(in_features=hidden_units*13*13,\n","                    out_features=output_shape)\n","      )\n","\n","  def forward(self, x: torch.Tensor):\n","      x = self.conv_block_1(x)\n","      x = self.conv_block_2(x)\n","      x = self.classifier(x)\n","      return x\n","      # return self.classifier(self.block_2(self.block_1(x))) # <- leverage the benefits of operator fusion"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tXOOAEHHc6-L","outputId":"2286ae24-37eb-4336-dded-c86cb9508e26","executionInfo":{"status":"ok","timestamp":1736554414104,"user_tz":480,"elapsed":602,"user":{"displayName":"Maohe Jiang","userId":"14592769344524725558"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["TinyVGG(\n","  (conv_block_1): Sequential(\n","    (0): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1))\n","    (1): ReLU()\n","    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n","    (3): ReLU()\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (conv_block_2): Sequential(\n","    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n","    (1): ReLU()\n","    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n","    (3): ReLU()\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (classifier): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=1690, out_features=3, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":14}],"source":["import torch\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","# Instantiate an instance of the model\n","torch.manual_seed(42)\n","model_0 = TinyVGG(input_shape=3, # number of color channels (3 for RGB)\n","                  hidden_units=10,\n","                  output_shape=len(train_data.classes)).to(device)\n","model_0"]},{"cell_type":"markdown","metadata":{"id":"C1CwvPiMcEfZ"},"source":["To test our model let's do a single forward pass (pass a sample batch from the training set through our model)."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"__p5G2ArcFko","outputId":"d9f521f6-b80d-48c2-85cb-9ac0c4e0291c","executionInfo":{"status":"ok","timestamp":1736554417834,"user_tz":480,"elapsed":1932,"user":{"displayName":"Maohe Jiang","userId":"14592769344524725558"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Single image shape: torch.Size([1, 3, 64, 64])\n","\n","Output logits:\n","tensor([[ 0.0208, -0.0020,  0.0095]], device='cuda:0')\n","\n","Output prediction probabilities:\n","tensor([[0.3371, 0.3295, 0.3333]], device='cuda:0')\n","\n","Output prediction label:\n","tensor([0], device='cuda:0')\n","\n","Actual label:\n","0\n"]}],"source":["# 1. Get a batch of images and labels from the DataLoader\n","img_batch, label_batch = next(iter(train_dataloader))\n","\n","# 2. Get a single image from the batch and unsqueeze the image so its shape fits the model\n","img_single, label_single = img_batch[0].unsqueeze(dim=0), label_batch[0]\n","print(f\"Single image shape: {img_single.shape}\\n\")\n","\n","# 3. Perform a forward pass on a single image\n","model_0.eval()\n","with torch.inference_mode():\n","    pred = model_0(img_single.to(device))\n","\n","# 4. Print out what's happening and convert model logits -> pred probs -> pred label\n","print(f\"Output logits:\\n{pred}\\n\")\n","print(f\"Output prediction probabilities:\\n{torch.softmax(pred, dim=1)}\\n\")\n","print(f\"Output prediction label:\\n{torch.argmax(torch.softmax(pred, dim=1), dim=1)}\\n\")\n","print(f\"Actual label:\\n{label_single}\")"]},{"cell_type":"markdown","source":["#### 3.2 scripts"],"metadata":{"id":"G3vkvBi8dcZN"}},{"cell_type":"code","source":["%%writefile /content/drive/MyDrive/pytorch/06_modular_py_models/model_builder.py\n","\n","\"\"\"\n","Contains PyTorch Code to define a TinyVGG model class\n","\"\"\"\n","\n","import torch\n","\n","from torch import nn\n","\n","print('I am a model')\n","\n","class TinyVGG(nn.Module):\n","  \"\"\"Creates the TinyVGG architecture.\n","\n","  Replicates the TinyVGG architecture from the CNN explainer website in PyTorch.\n","  See the original architecture here: https://poloclub.github.io/cnn-explainer/\n","\n","  Args:\n","    input_shape: An integer indicating number of input channels.\n","    hidden_units: An integer indicating number of hidden units between layers.\n","    output_shape: An integer indicating number of output units.\n","  \"\"\"\n","  def __init__(self, input_shape: int, hidden_units: int, output_shape: int) -> None:\n","      super().__init__()\n","      self.conv_block_1 = nn.Sequential(\n","          nn.Conv2d(in_channels=input_shape,\n","                    out_channels=hidden_units,\n","                    kernel_size=3, # how big is the square that's going over the image?\n","                    stride=1, # default\n","                    padding=0), # options = \"valid\" (no padding) or \"same\" (output has same shape as input) or int for specific number\n","          nn.ReLU(),\n","          nn.Conv2d(in_channels=hidden_units,\n","                    out_channels=hidden_units,\n","                    kernel_size=3,\n","                    stride=1,\n","                    padding=0),\n","          nn.ReLU(),\n","          nn.MaxPool2d(kernel_size=2,\n","                        stride=2) # default stride value is same as kernel_size\n","      )\n","      self.conv_block_2 = nn.Sequential(\n","          nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=0),\n","          nn.ReLU(),\n","          nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=0),\n","          nn.ReLU(),\n","          nn.MaxPool2d(2)\n","      )\n","      self.classifier = nn.Sequential(\n","          nn.Flatten(),\n","          # Where did this in_features shape come from?\n","          # It's because each layer of our network compresses and changes the shape of our inputs data.\n","          nn.Linear(in_features=hidden_units*13*13,\n","                    out_features=output_shape)\n","      )\n","\n","  def forward(self, x: torch.Tensor):\n","      x = self.conv_block_1(x)\n","      x = self.conv_block_2(x)\n","      x = self.classifier(x)\n","      return x\n","      # return self.classifier(self.block_2(self.block_1(x))) # <- leverage the benefits of operator fusion"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FDu-ZHFHdiHT","executionInfo":{"status":"ok","timestamp":1736568090642,"user_tz":480,"elapsed":150,"user":{"displayName":"Maohe Jiang","userId":"14592769344524725558"}},"outputId":"f757cd5a-f75a-42d5-877d-ea1631fba78f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting /content/drive/MyDrive/pytorch/06_modular_py_models/model_builder.py\n"]}]},{"cell_type":"markdown","source":["#### 3.3 use scripts"],"metadata":{"id":"TIz6mmMTef7G"}},{"cell_type":"code","source":["!python drive/MyDrive/pytorch/06_modular_py_models/model_builder.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zgmtdzyhd7zO","executionInfo":{"status":"ok","timestamp":1736568097896,"user_tz":480,"elapsed":4595,"user":{"displayName":"Maohe Jiang","userId":"14592769344524725558"}},"outputId":"d8577ee9-ec7e-4cf8-92eb-fd69ef961109"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["I am a model\n"]}]},{"cell_type":"code","source":["import model_builder\n","import torch\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","# Instantiate an instance of the model\n","torch.manual_seed(42)\n","model_0 = model_builder.TinyVGG(input_shape=3, # number of color channels (3 for RGB)\n","                                hidden_units=10,\n","                                output_shape=len(class_names)).to(device)\n","\n","\n","img_batch, label_batch = next(iter(train_loader))\n","\n","img_single, label_single = img_batch[0].unsqueeze(dim=0), label_batch[0]\n","print(f\"Single image shape: {img_single.shape}\\n\")\n","\n","model_0.eval()\n","with torch.inference_mode():\n","    pred = model_0(img_single.to(device))\n","\n","print(f\"Output logits:\\n{pred}\\n\")\n","print(f\"Output prediction probabilities:\\n{torch.softmax(pred, dim=1)}\\n\")\n","print(f\"Output prediction label:\\n{torch.argmax(torch.softmax(pred, dim=1), dim=1)}\\n\")\n","print(f\"Actual label:\\n{label_single}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IBZQkY9AeiDu","executionInfo":{"status":"ok","timestamp":1736568099478,"user_tz":480,"elapsed":538,"user":{"displayName":"Maohe Jiang","userId":"14592769344524725558"}},"outputId":"4d6acc44-f8d9-4561-9d23-8428e3cb2172"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["I am a model\n","Single image shape: torch.Size([1, 3, 64, 64])\n","\n","Output logits:\n","tensor([[ 0.0208, -0.0020,  0.0095]])\n","\n","Output prediction probabilities:\n","tensor([[0.3371, 0.3295, 0.3333]])\n","\n","Output prediction label:\n","tensor([0])\n","\n","Actual label:\n","0\n"]}]},{"cell_type":"markdown","metadata":{"id":"8OB4xIsXcHrp"},"source":["### 4. Define Utilities\n"," - Creating `train_step()` and `test_step()` functions and `train()` to combine them  \n"," - Save model"]},{"cell_type":"markdown","source":["#### 4.1 cells"],"metadata":{"id":"bovWqsXths_Z"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"t_0zRYZecJZ6"},"outputs":[],"source":["from typing import Tuple\n","\n","def train_step(model: torch.nn.Module,\n","               dataloader: torch.utils.data.DataLoader,\n","               loss_fn: torch.nn.Module,\n","               optimizer: torch.optim.Optimizer,\n","               device: torch.device) -> Tuple[float, float]:\n","  \"\"\"Trains a PyTorch model for a single epoch.\n","\n","  Turns a target PyTorch model to training mode and then\n","  runs through all of the required training steps (forward\n","  pass, loss calculation, optimizer step).\n","\n","  Args:\n","    model: A PyTorch model to be trained.\n","    dataloader: A DataLoader instance for the model to be trained on.\n","    loss_fn: A PyTorch loss function to minimize.\n","    optimizer: A PyTorch optimizer to help minimize the loss function.\n","    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n","\n","  Returns:\n","    A tuple of training loss and training accuracy metrics.\n","    In the form (train_loss, train_accuracy). For example:\n","\n","    (0.1112, 0.8743)\n","  \"\"\"\n","  # Put model in train mode\n","  model.train()\n","\n","  # Setup train loss and train accuracy values\n","  train_loss, train_acc = 0, 0\n","\n","  # Loop through data loader data batches\n","  for batch, (X, y) in enumerate(dataloader):\n","      # Send data to target device\n","      X, y = X.to(device), y.to(device)\n","\n","      # 1. Forward pass\n","      y_pred = model(X)\n","\n","      # 2. Calculate  and accumulate loss\n","      loss = loss_fn(y_pred, y)\n","      train_loss += loss.item()\n","\n","      # 3. Optimizer zero grad\n","      optimizer.zero_grad()\n","\n","      # 4. Loss backward\n","      loss.backward()\n","\n","      # 5. Optimizer step\n","      optimizer.step()\n","\n","      # Calculate and accumulate accuracy metric across all batches\n","      y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n","      train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n","\n","  # Adjust metrics to get average loss and accuracy per batch\n","  train_loss = train_loss / len(dataloader)\n","  train_acc = train_acc / len(dataloader)\n","  return train_loss, train_acc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sr_9AspYcKkW"},"outputs":[],"source":["def test_step(model: torch.nn.Module,\n","              dataloader: torch.utils.data.DataLoader,\n","              loss_fn: torch.nn.Module,\n","              device: torch.device) -> Tuple[float, float]:\n","  \"\"\"Tests a PyTorch model for a single epoch.\n","\n","  Turns a target PyTorch model to \"eval\" mode and then performs\n","  a forward pass on a testing dataset.\n","\n","  Args:\n","    model: A PyTorch model to be tested.\n","    dataloader: A DataLoader instance for the model to be tested on.\n","    loss_fn: A PyTorch loss function to calculate loss on the test data.\n","    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n","\n","  Returns:\n","    A tuple of testing loss and testing accuracy metrics.\n","    In the form (test_loss, test_accuracy). For example:\n","\n","    (0.0223, 0.8985)\n","  \"\"\"\n","  # Put model in eval mode\n","  model.eval()\n","\n","  # Setup test loss and test accuracy values\n","  test_loss, test_acc = 0, 0\n","\n","  # Turn on inference context manager\n","  with torch.inference_mode():\n","      # Loop through DataLoader batches\n","      for batch, (X, y) in enumerate(dataloader):\n","          # Send data to target device\n","          X, y = X.to(device), y.to(device)\n","\n","          # 1. Forward pass\n","          test_pred_logits = model(X)\n","\n","          # 2. Calculate and accumulate loss\n","          loss = loss_fn(test_pred_logits, y)\n","          test_loss += loss.item()\n","\n","          # Calculate and accumulate accuracy\n","          test_pred_labels = test_pred_logits.argmax(dim=1)\n","          test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n","\n","  # Adjust metrics to get average loss and accuracy per batch\n","  test_loss = test_loss / len(dataloader)\n","  test_acc = test_acc / len(dataloader)\n","  return test_loss, test_acc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-oze8b6icWE7"},"outputs":[],"source":["from typing import Dict, List\n","\n","from tqdm.auto import tqdm\n","\n","def train(model: torch.nn.Module,\n","          train_dataloader: torch.utils.data.DataLoader,\n","          test_dataloader: torch.utils.data.DataLoader,\n","          optimizer: torch.optim.Optimizer,\n","          loss_fn: torch.nn.Module,\n","          epochs: int,\n","          device: torch.device) -> Dict[str, List[float]]:\n","  \"\"\"Trains and tests a PyTorch model.\n","\n","  Passes a target PyTorch models through train_step() and test_step()\n","  functions for a number of epochs, training and testing the model\n","  in the same epoch loop.\n","\n","  Calculates, prints and stores evaluation metrics throughout.\n","\n","  Args:\n","    model: A PyTorch model to be trained and tested.\n","    train_dataloader: A DataLoader instance for the model to be trained on.\n","    test_dataloader: A DataLoader instance for the model to be tested on.\n","    optimizer: A PyTorch optimizer to help minimize the loss function.\n","    loss_fn: A PyTorch loss function to calculate loss on both datasets.\n","    epochs: An integer indicating how many epochs to train for.\n","    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n","\n","  Returns:\n","    A dictionary of training and testing loss as well as training and\n","    testing accuracy metrics. Each metric has a value in a list for\n","    each epoch.\n","    In the form: {train_loss: [...],\n","                  train_acc: [...],\n","                  test_loss: [...],\n","                  test_acc: [...]}\n","    For example if training for epochs=2:\n","                 {train_loss: [2.0616, 1.0537],\n","                  train_acc: [0.3945, 0.3945],\n","                  test_loss: [1.2641, 1.5706],\n","                  test_acc: [0.3400, 0.2973]}\n","  \"\"\"\n","  # Create empty results dictionary\n","  results = {\"train_loss\": [],\n","      \"train_acc\": [],\n","      \"test_loss\": [],\n","      \"test_acc\": []\n","  }\n","\n","  # Loop through training and testing steps for a number of epochs\n","  for epoch in tqdm(range(epochs)):\n","      train_loss, train_acc = train_step(model=model,\n","                                          dataloader=train_dataloader,\n","                                          loss_fn=loss_fn,\n","                                          optimizer=optimizer,\n","                                          device=device)\n","      test_loss, test_acc = test_step(model=model,\n","          dataloader=test_dataloader,\n","          loss_fn=loss_fn,\n","          device=device)\n","\n","      # Print out what's happening\n","      print(\n","          f\"Epoch: {epoch+1} | \"\n","          f\"train_loss: {train_loss:.4f} | \"\n","          f\"train_acc: {train_acc:.4f} | \"\n","          f\"test_loss: {test_loss:.4f} | \"\n","          f\"test_acc: {test_acc:.4f}\"\n","      )\n","\n","      # Update results dictionary\n","      results[\"train_loss\"].append(train_loss)\n","      results[\"train_acc\"].append(train_acc)\n","      results[\"test_loss\"].append(test_loss)\n","      results[\"test_acc\"].append(test_acc)\n","\n","  # Return the filled results at the end of the epochs\n","  return results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rFRZw6BZWWcd"},"outputs":[],"source":["from pathlib import Path\n","\n","def save_model(model: torch.nn.Module,\n","               target_dir: str,\n","               model_name: str):\n","  \"\"\"Saves a PyTorch model to a target directory.\n","\n","  Args:\n","    model: A target PyTorch model to save.\n","    target_dir: A directory for saving the model to.\n","    model_name: A filename for the saved model. Should include\n","      either \".pth\" or \".pt\" as the file extension.\n","\n","  Example usage:\n","    save_model(model=model_0,\n","               target_dir=\"models\",\n","               model_name=\"05_going_modular_tingvgg_model.pth\")\n","  \"\"\"\n","  # Create target directory\n","  target_dir_path = Path(target_dir)\n","  target_dir_path.mkdir(parents=True,\n","                        exist_ok=True)\n","\n","  # Create model save path\n","  assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\"), \"model_name should end with '.pt' or '.pth'\"\n","  model_save_path = target_dir_path / model_name\n","\n","  # Save the model state_dict()\n","  print(f\"[INFO] Saving model to: {model_save_path}\")\n","  torch.save(obj=model.state_dict(),\n","             f=model_save_path)"]},{"cell_type":"markdown","source":["#### 4.2 scripts"],"metadata":{"id":"B5CzfkXXhxtt"}},{"cell_type":"code","source":["%%writefile /content/drive/MyDrive/pytorch/06_modular_py_models/engine.py\n","\"\"\"\n","defiens the methods for training and saving model\n","\"\"\"\n","\n","from typing import Tuple, Dict, List\n","import torch\n","from torch import nn\n","from tqdm import tqdm\n","from pathlib import Path\n","\n","def train_step(model: torch.nn.Module,\n","               dataloader: torch.utils.data.DataLoader,\n","               loss_fn: torch.nn.Module,\n","               optimizer: torch.optim.Optimizer,\n","               device: torch.device) -> Tuple[float, float]:\n","  \"\"\"Trains a PyTorch model for a single epoch.\n","\n","  Turns a target PyTorch model to training mode and then\n","  runs through all of the required training steps (forward\n","  pass, loss calculation, optimizer step).\n","\n","  Args:\n","    model: A PyTorch model to be trained.\n","    dataloader: A DataLoader instance for the model to be trained on.\n","    loss_fn: A PyTorch loss function to minimize.\n","    optimizer: A PyTorch optimizer to help minimize the loss function.\n","    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n","\n","  Returns:\n","    A tuple of training loss and training accuracy metrics.\n","    In the form (train_loss, train_accuracy). For example:\n","\n","    (0.1112, 0.8743)\n","  \"\"\"\n","  # Put model in train mode\n","  model.train()\n","\n","  # Setup train loss and train accuracy values\n","  train_loss, train_acc = 0, 0\n","\n","  # Loop through data loader data batches\n","  for batch, (X, y) in enumerate(dataloader):\n","      # Send data to target device\n","      X, y = X.to(device), y.to(device)\n","\n","      # 1. Forward pass\n","      y_pred = model(X)\n","\n","      # 2. Calculate  and accumulate loss\n","      loss = loss_fn(y_pred, y)\n","      train_loss += loss.item()\n","\n","      # 3. Optimizer zero grad\n","      optimizer.zero_grad()\n","\n","      # 4. Loss backward\n","      loss.backward()\n","\n","      # 5. Optimizer step\n","      optimizer.step()\n","\n","      # Calculate and accumulate accuracy metric across all batches\n","      y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n","      train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n","\n","  # Adjust metrics to get average loss and accuracy per batch\n","  train_loss = train_loss / len(dataloader)\n","  train_acc = train_acc / len(dataloader)\n","  return train_loss, train_acc\n","\n","def test_step(model: torch.nn.Module,\n","              dataloader: torch.utils.data.DataLoader,\n","              loss_fn: torch.nn.Module,\n","              device: torch.device) -> Tuple[float, float]:\n","  \"\"\"Tests a PyTorch model for a single epoch.\n","\n","  Turns a target PyTorch model to \"eval\" mode and then performs\n","  a forward pass on a testing dataset.\n","\n","  Args:\n","    model: A PyTorch model to be tested.\n","    dataloader: A DataLoader instance for the model to be tested on.\n","    loss_fn: A PyTorch loss function to calculate loss on the test data.\n","    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n","\n","  Returns:\n","    A tuple of testing loss and testing accuracy metrics.\n","    In the form (test_loss, test_accuracy). For example:\n","\n","    (0.0223, 0.8985)\n","  \"\"\"\n","  # Put model in eval mode\n","  model.eval()\n","\n","  # Setup test loss and test accuracy values\n","  test_loss, test_acc = 0, 0\n","\n","  # Turn on inference context manager\n","  with torch.inference_mode():\n","      # Loop through DataLoader batches\n","      for batch, (X, y) in enumerate(dataloader):\n","          # Send data to target device\n","          X, y = X.to(device), y.to(device)\n","\n","          # 1. Forward pass\n","          test_pred_logits = model(X)\n","\n","          # 2. Calculate and accumulate loss\n","          loss = loss_fn(test_pred_logits, y)\n","          test_loss += loss.item()\n","\n","          # Calculate and accumulate accuracy\n","          test_pred_labels = test_pred_logits.argmax(dim=1)\n","          test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n","\n","  # Adjust metrics to get average loss and accuracy per batch\n","  test_loss = test_loss / len(dataloader)\n","  test_acc = test_acc / len(dataloader)\n","  return test_loss, test_acc\n","\n","def train(model: torch.nn.Module,\n","          train_dataloader: torch.utils.data.DataLoader,\n","          test_dataloader: torch.utils.data.DataLoader,\n","          optimizer: torch.optim.Optimizer,\n","          loss_fn: torch.nn.Module,\n","          epochs: int,\n","          device: torch.device) -> Dict[str, List[float]]:\n","  \"\"\"Trains and tests a PyTorch model.\n","\n","  Passes a target PyTorch models through train_step() and test_step()\n","  functions for a number of epochs, training and testing the model\n","  in the same epoch loop.\n","\n","  Calculates, prints and stores evaluation metrics throughout.\n","\n","  Args:\n","    model: A PyTorch model to be trained and tested.\n","    train_dataloader: A DataLoader instance for the model to be trained on.\n","    test_dataloader: A DataLoader instance for the model to be tested on.\n","    optimizer: A PyTorch optimizer to help minimize the loss function.\n","    loss_fn: A PyTorch loss function to calculate loss on both datasets.\n","    epochs: An integer indicating how many epochs to train for.\n","    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n","\n","  Returns:\n","    A dictionary of training and testing loss as well as training and\n","    testing accuracy metrics. Each metric has a value in a list for\n","    each epoch.\n","    In the form: {train_loss: [...],\n","                  train_acc: [...],\n","                  test_loss: [...],\n","                  test_acc: [...]}\n","    For example if training for epochs=2:\n","                 {train_loss: [2.0616, 1.0537],\n","                  train_acc: [0.3945, 0.3945],\n","                  test_loss: [1.2641, 1.5706],\n","                  test_acc: [0.3400, 0.2973]}\n","  \"\"\"\n","  # Create empty results dictionary\n","  results = {\"train_loss\": [],\n","      \"train_acc\": [],\n","      \"test_loss\": [],\n","      \"test_acc\": []\n","  }\n","\n","  # Loop through training and testing steps for a number of epochs\n","  for epoch in tqdm(range(epochs)):\n","      train_loss, train_acc = train_step(model=model,\n","                                          dataloader=train_dataloader,\n","                                          loss_fn=loss_fn,\n","                                          optimizer=optimizer,\n","                                          device=device)\n","      test_loss, test_acc = test_step(model=model,\n","          dataloader=test_dataloader,\n","          loss_fn=loss_fn,\n","          device=device)\n","\n","      # Print out what's happening\n","      print(\n","          f\"Epoch: {epoch+1} | \"\n","          f\"train_loss: {train_loss:.4f} | \"\n","          f\"train_acc: {train_acc:.4f} | \"\n","          f\"test_loss: {test_loss:.4f} | \"\n","          f\"test_acc: {test_acc:.4f}\"\n","      )\n","\n","      # Update results dictionary\n","      results[\"train_loss\"].append(train_loss)\n","      results[\"train_acc\"].append(train_acc)\n","      results[\"test_loss\"].append(test_loss)\n","      results[\"test_acc\"].append(test_acc)\n","\n","  # Return the filled results at the end of the epochs\n","  return results\n","\n","def save_model(model: torch.nn.Module,\n","               target_dir: str,\n","               model_name: str):\n","  \"\"\"Saves a PyTorch model to a target directory.\n","\n","  Args:\n","    model: A target PyTorch model to save.\n","    target_dir: A directory for saving the model to.\n","    model_name: A filename for the saved model. Should include\n","      either \".pth\" or \".pt\" as the file extension.\n","\n","  Example usage:\n","    save_model(model=model_0,\n","               target_dir=\"models\",\n","               model_name=\"05_going_modular_tingvgg_model.pth\")\n","  \"\"\"\n","  # Create target directory\n","  target_dir_path = Path(target_dir)\n","  target_dir_path.mkdir(parents=True,\n","                        exist_ok=True)\n","\n","  # Create model save path\n","  assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\"), \"model_name should end with '.pt' or '.pth'\"\n","  model_save_path = target_dir_path / model_name\n","\n","  # Save the model state_dict()\n","  print(f\"[INFO] Saving model to: {model_save_path}\")\n","  torch.save(obj=model.state_dict(),\n","             f=model_save_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CwoBLhdAhzTN","executionInfo":{"status":"ok","timestamp":1736568300867,"user_tz":480,"elapsed":163,"user":{"displayName":"Maohe Jiang","userId":"14592769344524725558"}},"outputId":"04ed96f1-c546-470a-d1de-02684a54dd6b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing /content/drive/MyDrive/pytorch/06_modular_py_models/engine.py\n"]}]},{"cell_type":"markdown","source":["#### 4.3 use scripts"],"metadata":{"id":"RpIQT4kxiXAu"}},{"cell_type":"code","source":["import engine\n","engine.train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":220},"id":"oKxD5GDWibaM","executionInfo":{"status":"ok","timestamp":1736568457777,"user_tz":480,"elapsed":170,"user":{"displayName":"Maohe Jiang","userId":"14592769344524725558"}},"outputId":"c6ee0160-33a5-4e71-8043-a93c4cc63c1b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<function engine.train(model: torch.nn.modules.module.Module, train_dataloader: torch.utils.data.dataloader.DataLoader, test_dataloader: torch.utils.data.dataloader.DataLoader, optimizer: torch.optim.optimizer.Optimizer, loss_fn: torch.nn.modules.module.Module, epochs: int, device: torch.device) -> Dict[str, List[float]]>"],"text/html":["<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n","      pre.function-repr-contents {\n","        overflow-x: auto;\n","        padding: 8px 12px;\n","        max-height: 500px;\n","      }\n","\n","      pre.function-repr-contents.function-repr-contents-collapsed {\n","        cursor: pointer;\n","        max-height: 100px;\n","      }\n","    </style>\n","    <pre style=\"white-space: initial; background:\n","         var(--colab-secondary-surface-color); padding: 8px 12px;\n","         border-bottom: 1px solid var(--colab-border-color);\"><b>engine.train</b><br/>def train(model: torch.nn.Module, train_dataloader: torch.utils.data.DataLoader, test_dataloader: torch.utils.data.DataLoader, optimizer: torch.optim.Optimizer, loss_fn: torch.nn.Module, epochs: int, device: torch.device) -&gt; Dict[str, List[float]]</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/drive/MyDrive/pytorch/06_modular_py_models/engine.py</a>Trains and tests a PyTorch model.\n","\n","Passes a target PyTorch models through train_step() and test_step()\n","functions for a number of epochs, training and testing the model\n","in the same epoch loop.\n","\n","Calculates, prints and stores evaluation metrics throughout.\n","\n","Args:\n","  model: A PyTorch model to be trained and tested.\n","  train_dataloader: A DataLoader instance for the model to be trained on.\n","  test_dataloader: A DataLoader instance for the model to be tested on.\n","  optimizer: A PyTorch optimizer to help minimize the loss function.\n","  loss_fn: A PyTorch loss function to calculate loss on both datasets.\n","  epochs: An integer indicating how many epochs to train for.\n","  device: A target device to compute on (e.g. &quot;cuda&quot; or &quot;cpu&quot;).\n","\n","Returns:\n","  A dictionary of training and testing loss as well as training and\n","  testing accuracy metrics. Each metric has a value in a list for\n","  each epoch.\n","  In the form: {train_loss: [...],\n","                train_acc: [...],\n","                test_loss: [...],\n","                test_acc: [...]}\n","  For example if training for epochs=2:\n","               {train_loss: [2.0616, 1.0537],\n","                train_acc: [0.3945, 0.3945],\n","                test_loss: [1.2641, 1.5706],\n","                test_acc: [0.3400, 0.2973]}</pre>\n","      <script>\n","      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n","        for (const element of document.querySelectorAll('.filepath')) {\n","          element.style.display = 'block'\n","          element.onclick = (event) => {\n","            event.preventDefault();\n","            event.stopPropagation();\n","            google.colab.files.view(element.textContent, 121);\n","          };\n","        }\n","      }\n","      for (const element of document.querySelectorAll('.function-repr-contents')) {\n","        element.onclick = (event) => {\n","          event.preventDefault();\n","          event.stopPropagation();\n","          element.classList.toggle('function-repr-contents-collapsed');\n","        };\n","      }\n","      </script>\n","      </div>"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["engine.save_model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":186},"id":"Y6o7pnCfjDtx","executionInfo":{"status":"ok","timestamp":1736568494238,"user_tz":480,"elapsed":171,"user":{"displayName":"Maohe Jiang","userId":"14592769344524725558"}},"outputId":"38db76c6-9f68-41b0-8679-752649e875ea"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<function engine.save_model(model: torch.nn.modules.module.Module, target_dir: str, model_name: str)>"],"text/html":["<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n","      pre.function-repr-contents {\n","        overflow-x: auto;\n","        padding: 8px 12px;\n","        max-height: 500px;\n","      }\n","\n","      pre.function-repr-contents.function-repr-contents-collapsed {\n","        cursor: pointer;\n","        max-height: 100px;\n","      }\n","    </style>\n","    <pre style=\"white-space: initial; background:\n","         var(--colab-secondary-surface-color); padding: 8px 12px;\n","         border-bottom: 1px solid var(--colab-border-color);\"><b>engine.save_model</b><br/>def save_model(model: torch.nn.Module, target_dir: str, model_name: str)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/drive/MyDrive/pytorch/06_modular_py_models/engine.py</a>Saves a PyTorch model to a target directory.\n","\n","Args:\n","  model: A target PyTorch model to save.\n","  target_dir: A directory for saving the model to.\n","  model_name: A filename for the saved model. Should include\n","    either &quot;.pth&quot; or &quot;.pt&quot; as the file extension.\n","\n","Example usage:\n","  save_model(model=model_0,\n","             target_dir=&quot;models&quot;,\n","             model_name=&quot;05_going_modular_tingvgg_model.pth&quot;)</pre>\n","      <script>\n","      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n","        for (const element of document.querySelectorAll('.filepath')) {\n","          element.style.display = 'block'\n","          element.onclick = (event) => {\n","            event.preventDefault();\n","            event.stopPropagation();\n","            google.colab.files.view(element.textContent, 196);\n","          };\n","        }\n","      }\n","      for (const element of document.querySelectorAll('.function-repr-contents')) {\n","        element.onclick = (event) => {\n","          event.preventDefault();\n","          event.stopPropagation();\n","          element.classList.toggle('function-repr-contents-collapsed');\n","        };\n","      }\n","      </script>\n","      </div>"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"20ZO64U2cZY_"},"source":["### 5. Train Model\n","\n","Let's leverage the functions we've got above to train, test and save a model to file.\n"]},{"cell_type":"markdown","source":["#### 5.1 cells"],"metadata":{"id":"K4t-yiRZnzPK"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":173,"referenced_widgets":["4b6de871b1624252bea8ee3dd6881793","27c9a83cb90b4fb6ba90f24bc5d7a043","3b04362a37fa4b0f9ed6e63d6b5d073c","ed9e619299724e87b29894eca99f0e65","0a8ac9a3257949138d08e5719f49685f","255c07179c0943d69d7d69ef7237853f","7a7a6844cdc94cea9efc531fea276fab","78b264ddbdff43e58fb3c92b244f157e","b171eedaee9f4b78b2a1052485fef279","cae8e891971549f3b52300b4e6c023da","337c8abdd632413a95214d06ab8bf1cc","803ff7aab243491e8451a74a5722b18d"]},"id":"FjeRMiLjccVc","outputId":"c29344f2-c3cf-4f35-9c2c-3bd9b1228cf6"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"803ff7aab243491e8451a74a5722b18d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/5 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch: 1 | train_loss: 1.0955 | train_acc: 0.3867 | test_loss: 1.0627 | test_acc: 0.4133\n","Epoch: 2 | train_loss: 1.0102 | train_acc: 0.5200 | test_loss: 1.0222 | test_acc: 0.4400\n","Epoch: 3 | train_loss: 0.9552 | train_acc: 0.5822 | test_loss: 1.0067 | test_acc: 0.4667\n","Epoch: 4 | train_loss: 0.8913 | train_acc: 0.5867 | test_loss: 1.0090 | test_acc: 0.4400\n","Epoch: 5 | train_loss: 0.8608 | train_acc: 0.6311 | test_loss: 1.0214 | test_acc: 0.4533\n","[INFO] Total training time: 5.859 seconds\n","[INFO] Saving model to: models/05_going_modular_cell_mode_tinyvgg_model.pth\n"]}],"source":["# Set random seeds\n","torch.manual_seed(42)\n","torch.cuda.manual_seed(42)\n","\n","# Set number of epochs\n","NUM_EPOCHS = 5\n","\n","# Recreate an instance of TinyVGG\n","model_0 = TinyVGG(input_shape=3, # number of color channels (3 for RGB)\n","                  hidden_units=10,\n","                  output_shape=len(train_data.classes)).to(device)\n","\n","# Setup loss function and optimizer\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(params=model_0.parameters(), lr=0.001)\n","\n","# Start the timer\n","from timeit import default_timer as timer\n","start_time = timer()\n","\n","# Train model_0\n","model_0_results = train(model=model_0,\n","                        train_dataloader=train_dataloader,\n","                        test_dataloader=test_dataloader,\n","                        optimizer=optimizer,\n","                        loss_fn=loss_fn,\n","                        epochs=NUM_EPOCHS,\n","                        device=device)\n","\n","# End the timer and print out how long it took\n","end_time = timer()\n","print(f\"[INFO] Total training time: {end_time-start_time:.3f} seconds\")\n","\n","# Save the model\n","model_save_path = data_path.parent / \"models\"\n","if not model_save_path.is_dir():\n","    model_save_path.mkdir()\n","\n","save_model(model = model_0,\n","           target_dir = model_save_path,\n","           model_name = \"06_modular_py_models_cells_tinyvgg.pth\")"]},{"cell_type":"markdown","source":["#### 5.2 scripts: it uses all parameters above"],"metadata":{"id":"4UP9xMzFnoNG"}},{"cell_type":"code","source":["%%writefile /content/drive/MyDrive/pytorch/06_modular_py_models/train.py\n","\n","\"\"\"\n","Trains a model given path for data\n","\n","example:\n","python train.py DATA_PATH\n","\"\"\"\n","\n","import os\n","import sys\n","import pathlib\n","import torch\n","from torch import nn\n","from torchvision import transforms\n","import data_download, data_setup, model_builder, engine\n","\n","def main():\n","    if len(sys.argv) < 2:\n","        print(\"Please provide a path\")\n","        return\n","\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","    data_path = sys.argv[1]\n","\n","    train_dir, eval_dir = data_download.download_sample_to_path(data_path)\n","\n","    transform = transforms.Compose([\n","        transforms.Resize((64, 64)),\n","        transforms.ToTensor()\n","    ])\n","\n","    train_loader, eval_loader, class_names = data_setup.create_dataloaders(train_dir, eval_dir,\n","                                                                           transform, 32, 0)\n","\n","    torch.manual_seed(42)\n","    torch.cuda.manual_seed(42)\n","\n","    # Set number of epochs\n","    NUM_EPOCHS = 5\n","\n","    model_0 = model_builder.TinyVGG(input_shape=3, # number of color channels (3 for RGB)\n","                  hidden_units=10,\n","                  output_shape=len(class_names)).to(device)\n","\n","    # Setup loss function and optimizer\n","    loss_fn = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.Adam(params=model_0.parameters(), lr=0.001)\n","\n","    # Start the timer\n","    from timeit import default_timer as timer\n","    start_time = timer()\n","\n","    # Train model_0\n","    model_0_results = engine.train(model=model_0,\n","                            train_dataloader=train_loader,\n","                            test_dataloader=eval_loader,\n","                            optimizer=optimizer,\n","                            loss_fn=loss_fn,\n","                            epochs=NUM_EPOCHS,\n","                            device=device)\n","\n","    # End the timer and print out how long it took\n","    end_time = timer()\n","    print(f\"[INFO] Total training time: {end_time-start_time:.3f} seconds\")\n","\n","    # Save the model\n","    model_save_path = pathlib.Path(data_path).parent / \"models\"\n","    if not model_save_path.is_dir():\n","        model_save_path.mkdir()\n","\n","    engine.save_model(model = model_0, target_dir = model_save_path,\n","                      model_name = \"6_modular_py_models_cells_tinyvgg.pth\")\n","\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JDVcHOIHn345","executionInfo":{"status":"ok","timestamp":1736571385407,"user_tz":480,"elapsed":184,"user":{"displayName":"Maohe Jiang","userId":"14592769344524725558"}},"outputId":"dd71592a-9cdf-4b2b-ab8f-a7b13688180e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting /content/drive/MyDrive/pytorch/06_modular_py_models/train.py\n"]}]}],"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/mrdbourke/pytorch-deep-learning/blob/main/going_modular/05_pytorch_going_modular_cell_mode.ipynb","timestamp":1736553926584}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0a8ac9a3257949138d08e5719f49685f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"255c07179c0943d69d7d69ef7237853f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27c9a83cb90b4fb6ba90f24bc5d7a043":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_255c07179c0943d69d7d69ef7237853f","placeholder":"","style":"IPY_MODEL_7a7a6844cdc94cea9efc531fea276fab","value":"100%"}},"337c8abdd632413a95214d06ab8bf1cc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3b04362a37fa4b0f9ed6e63d6b5d073c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_78b264ddbdff43e58fb3c92b244f157e","max":5,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b171eedaee9f4b78b2a1052485fef279","value":5}},"4b6de871b1624252bea8ee3dd6881793":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_27c9a83cb90b4fb6ba90f24bc5d7a043","IPY_MODEL_3b04362a37fa4b0f9ed6e63d6b5d073c","IPY_MODEL_ed9e619299724e87b29894eca99f0e65"],"layout":"IPY_MODEL_0a8ac9a3257949138d08e5719f49685f"}},"78b264ddbdff43e58fb3c92b244f157e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a7a6844cdc94cea9efc531fea276fab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b171eedaee9f4b78b2a1052485fef279":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cae8e891971549f3b52300b4e6c023da":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed9e619299724e87b29894eca99f0e65":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cae8e891971549f3b52300b4e6c023da","placeholder":"","style":"IPY_MODEL_337c8abdd632413a95214d06ab8bf1cc","value":" 5/5 [00:12&lt;00:00,  2.38s/it]"}}}},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}